# Multimodal LLM Interpretability

Этот репозиторий является решением тестового задания зимы 2025 в TLab.

## Оглавление
- [Multimodal LLM Interpretability](#multimodal-llm-interpretability)
  - [Оглавление](#оглавление)
  - [Установка, настройка и использование](#установка-настройка-и-использование)
    - [Предварительные требования](#предварительные-требования)
    - [Шаги](#шаги)
  - [Использование](#использование)
    - [1. Logit Lens](#1-logit-lens)
    - [2. Работа с полученным HTML-файлом](#2-работа-с-полученным-html-файлом)
    - [3. Анализ результатов](#3-анализ-результатов)
    - [4. Будущие исследования](#4-будущие-исследования)
  - [Контакты](#контакты)
  - [Ссылки](#ссылки)

## Установка, настройка и использование

### Предварительные требования
Убедитесь, что у вас установлен Python 3.8+ и `pip`.

### Шаги
1. **Клонируйте репозиторий:**
   ```bash
   git clone https://github.com/wolkendolf/tlab_MultimodalLLM.git
   mkdir save_folder
   cd tlab_MultimodalLLM
   ```

2. **Установите необходимые пакеты Python:**
    ```bash
    pip install -r requirements.txt
    ```

3. **Запустите эксперимент**
  В своей работе я провожу исследования с моделью `llava-1.5-7b`. Следующий код запускает модель и создает интерактивный HTML файл для иллюстрации работы logit lens. Если на одной GPU меньше 16Gb видеопамяти, используйте первую строку кода, иначе вторую. Флаг `CUDA_VISIBLE_DEVICES=0,1` указывает видеокарты, которые будут использоваться.

    ```bash
    CUDA_VISIBLE_DEVICES=0,1 python3 scripts/create_logit_lens.py --image_folder ./images --save_folder ./save_folder --device auto
    ```
    ```bash 
    python3 scripts/create_logit_lens.py --image_folder ./images --save_folder ./save_folder
    ```

## Использование
В быстро развивающемся ландшафте искусственного интеллекта многомодальные большие языковые модели становятся важной областью интереса. Эти модели, позволяющие объединить различные виды входных данных, становятся всё более популярными. Однако понимание их внутренних механизмов остается сложной задачей. В данной работе я исследую один из подходов анализа их внутренней работы - `Logit Lens`.

### 1. Logit Lens
LLM работает с двумя пространствами - исходным (vocab space) и латентным (embedding space), причем латентное пространство имеет меньшую размерность. Поскольку наша цель - лучше понимать процессы внутри нейронной сети, мы хотели бы уметь извлекать информацию из произвольного скрытого слоя. С этим нам поможет *Logit lens* - прием в исследовании интерпретируемости LLM, который фокусируется на том, во что «верит» LLM после каждого шага обработки, а не на том, как он обновляет это убеждение внутри шага.

В статье [1] есть хорошая иллюстрация этого метода (см. цифру 2 на картинке):

<img src="./images_for_readme/logit_lens_princ.jpg" width="700">

Суть заключается в том, что мы как бы через "микроскоп" ("lens") смотрим на то, как меняется ответ модели ("logit") слой за слоем. Более формальное описание:
Пусть $L$ - количество слоев в модели. На каждом слое происходит преобразование скрытых состояний:

```math
h^{(l)} = F^{(l)}\bigl(h^{(l-1)}\bigr), \quad l = 1, 2, \dots, L,
```
где функция $F^{(l)}$ включает механизмы самовнимания, нормализации и позиционно-зависимых нелинейных преобразований (feed-forward сети). Итоговое представление $h^{(L)}$ используется для генерации следующего токена. <br>
Итоговые логиты вычисляются, как проекция итогового представления $h^{(L)}$ в пространство словаря размерности $V$ с помощью линейного слоя, задаваемого матрицей весов $W \in \mathbb{R}^{V \times d}$ (а при наличии смещения --- вектором $b \in \mathbb{R}^{V}$):

```math
z = W\, h^{(L)} + b.
```
Вероятностное распределение по токенам вычисляется посредством функции softmax:

```math
p_i = \frac{\exp(z_i)}{\sum_{j=1}^{V} \exp(z_j)}, \quad i = 1, \dots, V.
```
Идея *logit lens* состоит в том, чтобы применять ту же линейную проекцию $W$ (и смещение $b$, если оно используется) к промежуточным представлениям $h^{(l)}$ для $l < L$. Таким образом, для каждого слоя $l$ определяется &laquo;промежуточное предсказание&raquo; в виде логитов:

```math
z^{(l)} = W\, h^{(l)} + b,
```
а затем соответствующее распределение по токенам:

```math
p^{(l)}_i = \frac{\exp(z^{(l)}_i)}{\sum_{j=1}^{V} \exp(z^{(l)}_j)}, \quad i = 1, \dots, V.
```

### 2. Работа с полученным HTML-файлом
При наведении курсора на изображение всплывает окно с информацией о:
 - номере слоя, где модель достигает наибольшей уверенности в ответе;
 - соответствующие слою топ-5 токенов по принципу "токен" : "уверенность модели в ответе".  
  <img src="./images_for_readme/work_with_html.png" width="400">

При наведении курсора на ячейку таблицы выводится аналогичная информация.

Зафиксировать интересующую область картинки для анализа можно кликом мыши. Повторный клик снимает фиксацию.

### 3. Анализ результатов
1) Наибольшей уверенности модель стабильно достигает в последней трети слоев. Это можно видеть по номеру слоя при наведении курсора на картинку. Отсюда можно сделать вывод, что информация об объекте в значительной степени локализована в токенах, соответствующих пространственному местоположению объекта на исходном изображении.
2) Я заметил, что если объект на картинке протяженный, то модель дает наиболее разумные ответы для токенов, находящихся ближе к его границе. Это может говорить о том, что более значимые токены расположены ближе к границе объекта, а менее значимые - внутри его контура. Чтобы проверить свою гипотезу я добавил маску поверх каждого изображения, закрасив черным те токены, которые модель классифицирует пустой строкой "" (см. картинку). Видно, что гипотеза нашла свое подтверждение: небо и фон объектов оказались сильно закрашены. Это указывает на неравномерное распределение вклада различных регионов изображения: модель «фокусируется» на границах, где, вероятно, наблюдаются наиболее резкие изменения признаков (цвета, текстуры, формы). <br>
<img src="./images_for_readme/masked_images.jpg" width="600">

3) Обработка изображения происходит на разных масштабах. Это можно увидеть в файле `llava-1.5-7b-hf_sweater_logit_lens.html`, где один из токенов распознается как **ant**-lers (рога), а другой - как **swe**-ater (свитер). <br>
  <img src="./images_for_readme/sweater1.png" width="400">
  <img src="./images_for_readme/sweater2.png" width="400">

4) Можно заметить, что при декодировании в начальных слоях могут встречаться символы, отличные от английского алфавита. Ближе к последним слоям мы всегда получаем читабельный текст. Такой эффект можно объяснить тем, что в средних слоях трансформер работает в абстрактном "пространстве понятий" (“concept space”) *[2]*, которое только в последних слоях переходит в "пространство токенов" ("token space") *[2]* конкретного, в нашем случае английского, языка.

### 4. Будущие исследования
- Рассмотреть возможность включения алгоритмов детекции контуров или других методов выделения границ в архитектуру модели. Если модель действительно использует границы как ключевой источник информации, то явное выделение таких признаков может повысить как интерпретируемость, так и качество распознавания.
- Проверить гипотезу о фокусировании модели на определенных частях картинки в задаче лейблинга с помощью других инструментов. Например, один из них представлен в статье [3], но к сожалению, я не смог его запустить. Часть используемых библиотек не было в pip, а если были, то не было нескольких используемых функций.
- Рассмотреть отличные от *logit lens* приемы анализа работы LVLM, как "attention knockout" [4], где некоторые токены удаляются, чтобы оценить их важность.
  

## Контакты
Tg: [@Dan_i_il](@Dan_i_il)

## Ссылки
[1] - [Clement et al. (2024). Towards Interpreting Visual Information Processing in Vision-Language Models](https://arxiv.org/abs/2410.07149) \
[2] - [Wendler et al. (2024). Do Llamas Work in {E}nglish? On the Latent Language of Multilingual Transformers](https://aclanthology.org/2024.acl-long.820/) \
[3] - [Stan et al. (2024). LVLM Interpret: An Interpretability Tool for Large Vision-Language Models](https://intellabs.github.io/multimodal_cognitive_ai/lvlm_interpret/) \
[4] - [Geva et al. (2023). Dissecting recall of factual associations in auto-regressive language models](https://arxiv.org/abs/2304.14767) \